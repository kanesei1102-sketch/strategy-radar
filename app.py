import streamlit as st
import pandas as pd
from openai import OpenAI
from tavily import TavilyClient
import datetime

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="Strategic Intelligence Radar", layout="wide")

st.title("ğŸ“¡ Strategic Intelligence Radar")
st.caption("æœ€æ–°æ–‡çŒ®ãƒ»æŠ€è¡“æƒ…å ±ã®ã€Œåé›†ã€ã¨ã€ŒæŸ»å®šã€ã‚’è‡ªå‹•åŒ–ã™ã‚‹")

# --- APIã‚­ãƒ¼ã®ç¢ºèª ---
if "TAVILY_API_KEY" not in st.secrets or "OPENAI_API_KEY" not in st.secrets:
    st.error("APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚Secretsã«TAVILY_API_KEYã¨OPENAI_API_KEYã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()

tavily = TavilyClient(api_key=st.secrets["TAVILY_API_KEY"])
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šæ¤œç´¢è¨­å®š ---
with st.sidebar:
    st.header("Search Parameters")
    
    # æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    query = st.text_input("æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰:", value="Thymic regeneration cell sheet engineering")
    
    # æ¤œç´¢ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    days_back = st.slider("æ¤œç´¢ç¯„å›²ï¼ˆéå»næ—¥ï¼‰:", 1, 365, 30)
    max_results = st.slider("å–å¾—ä»¶æ•°:", 3, 20, 5)
    
    # æŸ»å®šåŸºæº–ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«åŸ‹ã‚è¾¼ã‚€ï¼‰
    focus_point = st.text_area("æŸ»å®šã®é‡ç‚¹ãƒã‚¤ãƒ³ãƒˆ:", 
                               value="èƒ¸è…ºä¸Šçš®ç´°èƒã®åˆ†åŒ–èª˜å°åŠ¹ç‡ã€ã¾ãŸã¯ç´°èƒã‚·ãƒ¼ãƒˆã®ç©å±¤æŠ€è¡“ã«é–¢ã™ã‚‹æ–°è¦æ€§ãŒã‚ã‚‹ã‹ï¼Ÿ")

    search_btn = st.button("ãƒ¬ãƒ¼ãƒ€ãƒ¼ç…§å°„ (æ¤œç´¢é–‹å§‹)")

# --- ãƒ¡ã‚¤ãƒ³ï¼šæ¤œç´¢ã¨æŸ»å®š ---
if search_btn:
    with st.spinner(f"Webç©ºé–“ã‚’ã‚¹ã‚­ãƒ£ãƒ³ä¸­... ({query})"):
        # 1. Tavilyã§æ¤œç´¢å®Ÿè¡Œ
        try:
            response = tavily.search(
                query=query, 
                search_depth="advanced", 
                max_results=max_results,
                include_domains=["nature.com", "sciencedirect.com", "pubmed.ncbi.nlm.nih.gov", "wiley.com", "biorxiv.org"], # å­¦è¡“ç³»ã«çµã‚‹ä¾‹
                # exclude_domains=[] 
            )
            results = response.get("results", [])
        except Exception as e:
            st.error(f"æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            st.stop()

    if not results:
        st.warning("é–¢é€£æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å¤‰ãˆã¦ã¿ã¦ãã ã•ã„ã€‚")
    else:
        st.success(f"{len(results)} ä»¶ã®æƒ…å ±ã‚’æ•æ‰ã€‚AIæŸ»å®šã‚’é–‹å§‹ã—ã¾ã™...")
        
        # çµæœæ ¼ç´ç”¨ãƒªã‚¹ãƒˆ
        analyzed_data = []
        progress_bar = st.progress(0)

        for i, res in enumerate(results):
            with st.spinner(f"Analyzing: {res['title'][:20]}..."):
                # 2. GPT-4oã«ã‚ˆã‚‹æŸ»å®š
                prompt = f"""
                ã‚ãªãŸã¯å†ç”ŸåŒ»ç™‚åˆ†é‡ã®å°‚é–€å®¶ï¼ˆPIï¼‰ã§ã™ã€‚ä»¥ä¸‹ã®æ–‡çŒ®æƒ…å ±ã‚’èª­ã¿ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã€Œé‡ç‚¹ãƒã‚¤ãƒ³ãƒˆã€ã«åŸºã¥ã„ã¦æŸ»å®šã—ã¦ãã ã•ã„ã€‚
                
                ã€é‡ç‚¹ãƒã‚¤ãƒ³ãƒˆã€‘
                {focus_point}

                ã€æ–‡çŒ®æƒ…å ±ã€‘
                ã‚¿ã‚¤ãƒˆãƒ«: {res['title']}
                å†…å®¹ã‚¹ãƒ‹ãƒšãƒƒãƒˆ: {res['content']}
                URL: {res['url']}

                ã€å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‘
                ä»¥ä¸‹ã®å½¢å¼ã§æ—¥æœ¬èªã§å‡ºåŠ›ã›ã‚ˆã€‚ä½™è¨ˆãªå‰ç½®ãã¯ä¸è¦ã€‚
                
                åˆ¤å®šãƒ©ãƒ³ã‚¯: (S: å¿…èª­ / A: æœ‰ç›Š / B: å‚è€ƒç¨‹åº¦ / C: ç„¡é–¢ä¿‚)
                è¦ç´„: (50æ–‡å­—ä»¥å†…ã§ç°¡æ½”ã«)
                ç†ç”±: (ãªãœãã®ãƒ©ãƒ³ã‚¯ãªã®ã‹ã€é‡ç‚¹ãƒã‚¤ãƒ³ãƒˆã¨ã©ã†é–¢ã‚ã‚‹ã‹)
                """

                ai_res = client.chat.completions.create(
                    model="gpt-4o",
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.3
                )
                
                analysis_text = ai_res.choices[0].message.content
                
                # ãƒ©ãƒ³ã‚¯ã®æŠ½å‡ºï¼ˆç°¡æ˜“çš„ï¼‰
                rank = "B"
                if "åˆ¤å®šãƒ©ãƒ³ã‚¯: S" in analysis_text: rank = "S"
                elif "åˆ¤å®šãƒ©ãƒ³ã‚¯: A" in analysis_text: rank = "A"
                elif "åˆ¤å®šãƒ©ãƒ³ã‚¯: C" in analysis_text: rank = "C"

                analyzed_data.append({
                    "Rank": rank,
                    "Title": res['title'],
                    "Analysis": analysis_text,
                    "URL": res['url']
                })
                
            progress_bar.progress((i + 1) / len(results))

        # --- çµæœè¡¨ç¤º ---
        st.divider()
        st.subheader("ğŸ“¡ Intelligence Report")

        # ãƒ©ãƒ³ã‚¯ã§ã‚½ãƒ¼ãƒˆï¼ˆSãŒä¸Šã«æ¥ã‚‹ã‚ˆã†ã«ï¼‰
        rank_order = {"S": 0, "A": 1, "B": 2, "C": 3}
        analyzed_data.sort(key=lambda x: rank_order.get(x["Rank"], 4))

        for item in analyzed_data:
            # ãƒ©ãƒ³ã‚¯ã”ã¨ã®è‰²åˆ†ã‘
            color = "gray"
            if item["Rank"] == "S": color = "red"
            elif item["Rank"] == "A": color = "orange"
            elif item["Rank"] == "B": color = "blue"

            with st.expander(f"ã€{item['Rank']}ã€‘ {item['Title']}", expanded=(item["Rank"] in ["S", "A"])):
                st.markdown(f"**URL**: {item['URL']}")
                st.markdown(f"**AIæŸ»å®š**:\n{item['Analysis']}")
                if item["Rank"] == "S":
                    st.error("ğŸ”¥ ã“ã‚Œã¯ã€Œé‡ç‚¹ãƒã‚¤ãƒ³ãƒˆã€ã«æ·±ãåˆºã•ã‚‹é‡è¦æ–‡çŒ®ã§ã™ï¼")

        # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        df = pd.DataFrame(analyzed_data)
        csv = df.to_csv(index=False).encode('utf-8')
        st.download_button("ãƒ¬ãƒãƒ¼ãƒˆã‚’CSVã§ä¿å­˜", csv, f"radar_report_{datetime.date.today()}.csv", "text/csv")
